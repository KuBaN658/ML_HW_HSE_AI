# Отчет по обучению линейной модели для предсказания стоимости автомобилей

## Введение

Для построения модели предсказания стоимости автомобилей использовались линейные регрессионные модели. Основное внимание уделялось исследованию влияния различных признаков, методов их трансформации и регуляризации на качество предсказания. Оценка качества проводилась с использованием метрик RMSE и R², а также скорректированной метрики \( R^2_{adj} \), которая учитывает размерность выборки.

---

## Этапы работы

### 1. Базовая линейная модель
- Обучена классическая линейная регрессия с дефолтными параметрами.
- **Результат**: базовая модель служила ориентиром для сравнения с другими подходами.

---

### 2. Линейная модель на масштабированных данных
- Данные были масштабированы.
- **Результат**: качество модели практически не изменилось.
- Выявлено, что признак `max_power` оказывает наибольшее влияние на предсказания.

---

### 3. Lasso-регрессия
- Обучена Lasso-регрессия с коэффициентом регуляризации \( \alpha = 1 \) (по умолчанию).
- **Результат**: ни один из весов не был обнулен, так как все признаки были информативными для модели.

#### Подбор параметров регуляризации
- Использован `GridSearchCV` для Lasso и ElasticNet.
- **Лучшие параметры**:
  - **Lasso**: \( \alpha = 10 \).
  - **ElasticNet**: \( \alpha = 0.621 \), \( l1\_ratio = 0.821 \).
- **Результат**: ElasticNet показала значительно худшее качество, чем Lasso.

---

### 4. L0-регуляризация
- Реализована модель с L0-регуляризацией.
- **Результат**: модель начала отбрасывать признаки только при очень высоких значениях коэффициента регуляризации, что подтверждает высокую информативность всех признаков.

---

### 5. Добавление категориальных переменных
- Категориальные переменные закодированы с помощью `OneHotEncoder`.
- Подобран параметр \( \alpha = 0.0001 \) для Ridge-регрессии с использованием кросс-валидации.
- **Результат**: \( R^2 \) > 0.74, что значительно лучше предыдущих моделей.

---

### 6. Добавление новых признаков
- Добавлены собственные признаки:
  - Обратная пропорциональность от пробега.
  - Отношение мощности к объему двигателя.
  - Логарифм пробега.
  - Логарифм мощности двигателя.
- Сгенерированы полиномиальные признаки с использованием `PolynomialFeatures` (количество признаков увеличилось до более 1000).
- Обучена Lasso-регрессия с \( \alpha = 10 \).
- **Результат**: \( R^2 \) > 0.95 на тестовой выборке.
- Удалены признаки с обнуленными весами. После этого:
  - Подобран \( \alpha = 10 \) для Ridge-регрессии.
  - **Результат**: качество лишь незначительно снизилось по сравнению с моделью без удаления признаков.

---

### 7. Финальный Pipeline
- Реализован `Pipeline` на основе последней модели с небольшими изменениями.
- **Результат**: \( R^2 \) > 0.96 на тестовой выборке.

---

## Заключение
Работа показала успешное применение линейных моделей для предсказания стоимости автомобилей. Итоговый `Pipeline` с учетом новых признаков, полиномиальных преобразований и оптимальных параметров регуляризации обеспечил высокое качество предсказаний (\( R^2 \) > 0.96). Мы остались довольны результатом.
## Пример работы сервиса
![](https://github.com/KuBaN658/ML_HW_HSE_AI/blob/main/hw1/img/Screenshot%20from%202024-11-23%2012-43-56.png)
![](https://github.com/KuBaN658/ML_HW_HSE_AI/blob/main/hw1/img/Screenshot%20from%202024-11-23%2012-47-59.png)
